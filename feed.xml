<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.6">Jekyll</generator><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/" rel="alternate" type="text/html" /><updated>2020-03-29T13:44:09+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/</id><title type="html">wjohn1483.github.io</title><subtitle></subtitle><author><name>Your Name</name></author><entry><title type="html">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/29/BERT-pre-training-of-deep-bidirectional-transforers-for-language-understanding/" rel="alternate" type="text/html" title="BERT&amp;#58; Pre-training of Deep Bidirectional Transformers for Language Understanding" /><published>2020-03-29T00:00:00+00:00</published><updated>2020-03-29T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/29/BERT-pre-training-of-deep-bidirectional-transforers-for-language-understanding</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/29/BERT-pre-training-of-deep-bidirectional-transforers-for-language-understanding/">&lt;p&gt;這篇介紹一下常常聽到的&lt;a href=&quot;https://arxiv.org/pdf/1810.04805.pdf&quot;&gt;BERT&lt;/a&gt;是怎麼樣運作的。&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;簡介&quot;&gt;簡介&lt;/h2&gt;

&lt;p&gt;在很多NLP的任務上常常可以聽到某個團隊用了BERT以後達到了state-of-the-art，而聽說現在在做NLP的時候都會使用BERT產生出來的embedding，再拿去給後面想要解決的NLP任務使用，得到的效果通常都還不錯，BERT成為了做各種NLP任務的起手式。&lt;/p&gt;

&lt;h2 id=&quot;方法&quot;&gt;方法&lt;/h2&gt;

&lt;p&gt;BERT的架構是前一篇&lt;a href=&quot;https://wjohn1483.github.io/2020/03/21/attention-is-all-you-need/&quot;&gt;Attention Is All You Need&lt;/a&gt;當中所提到的Transformer的encoder，只是訓練的方式和參數的設定比較不一樣，在BERT這篇paper裡面使用了兩種參數&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathrm{BERT}_{BASE}:L=12,H=768,A=12, total\ parameters=110\mathrm{M}\\\mathrm{BERT}_{LARGE}:L=24,H=1024,A=16, total\ parameters=340\mathrm{M}&lt;/script&gt;

&lt;p&gt;其中&lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;代表層數、&lt;script type=&quot;math/tex&quot;&gt;H&lt;/script&gt;代表hidden size、&lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt;代表self-attention的head數。&lt;/p&gt;

&lt;h3 id=&quot;訓練方式&quot;&gt;訓練方式&lt;/h3&gt;

&lt;h4 id=&quot;input-representation&quot;&gt;Input Representation&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;input-representation.png&quot; alt=&quot;Input Representation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;由於BERT後面所接的NLP任務可能會需要sentence embedding，或同時考慮多個sentence，所以BERT在這個地方有設計兩個特別的token，分別是&lt;code class=&quot;highlighter-rouge&quot;&gt;[CLS]&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;[SEP]&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;[SEP]&lt;/code&gt;是用來分開兩個句子的，而&lt;code class=&quot;highlighter-rouge&quot;&gt;[CLS]&lt;/code&gt;是用來做classification的embedding，因為BERT是用self-attention layer為基礎，所以即便放在第一個，其輸出的embedding仍然包含整個句子的資訊。&lt;/p&gt;

&lt;p&gt;而上圖中的Segment Embeddings是為了能夠更分開兩個句子之間的差異，可以想像成&lt;script type=&quot;math/tex&quot;&gt;\mathrm{E_A}&lt;/script&gt;是一個純量等於&lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt;，&lt;script type=&quot;math/tex&quot;&gt;\mathrm{E_B}&lt;/script&gt;也是一個純量等於&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt;，更詳細的解說可以參考&lt;a href=&quot;https://www.cnblogs.com/d0main/p/10447853.html&quot;&gt;這裡&lt;/a&gt;。&lt;/p&gt;

&lt;h4 id=&quot;masked-lm&quot;&gt;Masked LM&lt;/h4&gt;

&lt;p&gt;BERT在做pre-training的時候，會同時訓練兩種任務，分別是masked LM以及next sentence prediction，而masked LM做的事情有點像是克漏字，在輸入一段文字進來的時候，在每個token會有15%的機率會被替換成&lt;code class=&quot;highlighter-rouge&quot;&gt;[MASK]&lt;/code&gt;這個token，而最終希望透過一個classifier，輸入&lt;code class=&quot;highlighter-rouge&quot;&gt;[MASK]&lt;/code&gt;經過BERT得到的embedding，輸出原本被替換掉的token。&lt;/p&gt;

&lt;h4 id=&quot;next-sentence-prediction-nsp&quot;&gt;Next Sentence Prediction (NSP)&lt;/h4&gt;

&lt;p&gt;Next sentence prediction做的事情就是去判斷輸入進來的這兩個句子，是不是在順序上是連續的，像是&lt;code class=&quot;highlighter-rouge&quot;&gt;人之初&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;性本善&lt;/code&gt;就是連續的句子，但&lt;code class=&quot;highlighter-rouge&quot;&gt;人之初&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;你好嗎&lt;/code&gt;就不是連續的句子，而訓練的方式是會拿&lt;code class=&quot;highlighter-rouge&quot;&gt;[CLS]&lt;/code&gt;經過BERT得出來的embedding，來當作classifier的輸入，希望這個classifier輸出&lt;script type=&quot;math/tex&quot;&gt;\mathrm{IsNext}&lt;/script&gt;或是&lt;script type=&quot;math/tex&quot;&gt;\mathrm{NotNext}&lt;/script&gt;。&lt;/p&gt;

&lt;p&gt;底下是整體的架構圖，其實在fine-tuning的時候，會根據不一樣的任務而拿不同位置輸出的結果，細節可以參考&lt;a href=&quot;https://arxiv.org/pdf/1810.04805.pdf&quot;&gt;原本的paper&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;overall-procedure.png&quot; alt=&quot;Overall procedure&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;實驗&quot;&gt;實驗&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;test-results.png&quot; alt=&quot;Test Results&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上圖為BERT部分的實驗結果，可以看到它技壓群雄。&lt;/p&gt;

&lt;h2 id=&quot;結論&quot;&gt;結論&lt;/h2&gt;

&lt;p&gt;BERT是一個基於Transformer架構的模型，需要大量的資料來做訓練，好在作者們有提供已經訓練好的模型參數，可以直接下載下來做使用，期望使用BERT以後，能夠讓想要解決的NLP任務結果一飛沖天。&lt;/p&gt;

&lt;h2 id=&quot;參考資料&quot;&gt;參考資料&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/d0main/p/10447853.html&quot;&gt;【译】为什么BERT有3个嵌入层，它们都是如何实现的&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Your Name</name></author><category term="Paper" /><summary type="html">這篇介紹一下常常聽到的BERT是怎麼樣運作的。</summary></entry><entry><title type="html">Terminal小工具</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/28/terminal-tools/" rel="alternate" type="text/html" title="Terminal小工具" /><published>2020-03-28T00:00:00+00:00</published><updated>2020-03-28T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/28/terminal-tools</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/28/terminal-tools/">&lt;p&gt;這篇記錄一下我在terminal裡面常使用的一些小工具們。&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;terminal&quot;&gt;Terminal&lt;/h2&gt;

&lt;p&gt;Terminal又稱為終端機，是一個可以用指令跟電腦做溝通、操縱的介面，是個絕大多數工程師都曾使用過的東西，如果你的電腦使用的是Linux系統的話，原生就有terminal了，底下稍微介紹一下在各個系統安裝terminal的方法。&lt;/p&gt;

&lt;h3 id=&quot;cygwin&quot;&gt;Cygwin&lt;/h3&gt;

&lt;p&gt;在Windows系統上原生也有一個&lt;code class=&quot;highlighter-rouge&quot;&gt;命令提示字元&lt;/code&gt;，雖然它外表跟terminal長得蠻像的，但裡面的指令跟大多數的terminal有蠻大的差異，如果你想要在windows系統上也能夠使用terminal的話，我推薦安裝&lt;a href=&quot;https://www.cygwin.com/&quot;&gt;Cygwin&lt;/a&gt;，只需要去其網站上下載&lt;a href=&quot;https://www.cygwin.com/setup-x86_64.exe&quot;&gt;setup-x86_64&lt;/a&gt;，照著步驟做應該就能安裝好了。&lt;/p&gt;

&lt;p&gt;如果想要安裝其他套件，像是vim、git等等，可以再次執行&lt;a href=&quot;https://www.cygwin.com/setup-x86_64.exe&quot;&gt;setup-x86_64&lt;/a&gt;，並在裡面勾選，或是安裝&lt;code class=&quot;highlighter-rouge&quot;&gt;apt-cyg&lt;/code&gt;，在裡面用指令來安裝。&lt;/p&gt;

&lt;h4 id=&quot;安裝apt-cyg&quot;&gt;安裝apt-cyg&lt;/h4&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;wget https://raw.githubusercontent.com/transcode-open/apt-cyg/master/apt-cyg
&lt;span class=&quot;nb&quot;&gt;chmod&lt;/span&gt; +x apt-cyg
&lt;span class=&quot;nb&quot;&gt;mv &lt;/span&gt;apt-cyg /usr/local/bin
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;安裝完成以後就能夠使用底下的指令來安裝其他的套件了。&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apt-cyg &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;nano
apt-cyg &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;git
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;iterm&quot;&gt;iTerm&lt;/h3&gt;

&lt;p&gt;在Mac裡面也有原生的&lt;code class=&quot;highlighter-rouge&quot;&gt;終端機&lt;/code&gt;，但蠻多人都推薦在Mac上使用&lt;a href=&quot;https://www.iterm2.com/&quot;&gt;iTerm2&lt;/a&gt;，你可以使用&lt;a href=&quot;https://brew.sh/index_zh-tw.html&quot;&gt;Homebrew&lt;/a&gt;來安裝。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;安裝Homebrew&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; /bin/bash &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;curl &lt;span class=&quot;nt&quot;&gt;-fsSL&lt;/span&gt; https://raw.githubusercontent.com/Homebrew/install/master/install.sh&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;安裝iTerm2&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;brew cask &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;iterm2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;bash&quot;&gt;Bash&lt;/h2&gt;

&lt;p&gt;如果你的系統上面只能允許你使用bash的話，我自己個人會建議將底下的東西放入你的&lt;strong&gt;~/.bashrc&lt;/strong&gt;檔裡。&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;TERM&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;xterm-256color
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PS1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;[&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\u&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\h&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\W&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\\&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\[&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;tput sgr0&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\]&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上面的動作可以使你的terminal能顯示256色，可以透過&lt;a href=&quot;http://www.robmeerman.co.uk/_media/unix/256colors2.pl&quot;&gt;這個script&lt;/a&gt;，搭配底下的指令&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;perl 256colors2.pl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;來檢驗你的terminal是否有支援256色，於此同時將命令列調整成&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;使用者名稱@電腦名稱 當前目錄]&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;比較易於使用。&lt;/p&gt;

&lt;h2 id=&quot;zsh&quot;&gt;ZSH&lt;/h2&gt;

&lt;p&gt;若你的環境允許你安裝其他東西的話，會建議將原生的bash替換成zsh，安裝方法如下&lt;/p&gt;

&lt;h4 id=&quot;cygwin-1&quot;&gt;Cygwin&lt;/h4&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;apt-cyg &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;zsh curl git
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;iterm-1&quot;&gt;iTerm&lt;/h4&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;brew &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;zsh zsh-completions
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;切換預設的shell&quot;&gt;切換預設的shell&lt;/h4&gt;

&lt;p&gt;若想要將預設的bash換成zsh的話，可以利用底下的指令&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;chsh &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;which zsh&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;並利用&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$SHELL&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;來確認是否有切換成功。&lt;/p&gt;

&lt;h3 id=&quot;oh-my-zsh&quot;&gt;oh-my-zsh&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/ohmyzsh/ohmyzsh&quot;&gt;oh-my-zsh&lt;/a&gt;是一個管理zsh的框架，提供了蠻多套件和主題可以使用，只需要打上底下的指令就能安裝好了。&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sh &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;wget &lt;span class=&quot;nt&quot;&gt;-O-&lt;/span&gt; https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;zsh-autosuggestions&quot;&gt;zsh-autosuggestions&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zsh-users/zsh-autosuggestions&quot;&gt;zsh-autosuggestions&lt;/a&gt;是一個zsh的套件，可以根據你以前打過的指令去猜測你現在要打的指令，安裝方法如下&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;下載zsh-autosuggestions&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone https://github.com/zsh-users/zsh-autosuggestions &lt;span class=&quot;nv&quot;&gt;$ZSH_CUSTOM&lt;/span&gt;/plugins/zsh-autosuggestions
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改&lt;strong&gt;~/.zshrc&lt;/strong&gt;，找到設定檔中&lt;code class=&quot;highlighter-rouge&quot;&gt;plugins=(git)&lt;/code&gt;的部分，將之修改成以下&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;plugins&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=(&lt;/span&gt;
     git
     zsh-autosuggestions
&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重新載入zsh&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; ~/.zshrc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;zsh-syntax-highlighting&quot;&gt;zsh-syntax-highlighting&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zsh-users/zsh-syntax-highlighting&quot;&gt;zsh-syntax-highlighting&lt;/a&gt;是個在zsh裡面幫你highlight一些指令、路徑等參數的套件，安裝方法如下&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;下載zsh-syntax-highlighting&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone https://github.com/zsh-users/zsh-syntax-highlighting.git &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;ZSH_CUSTOM&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;~/.oh-my-zsh/custom&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/plugins/zsh-syntax-highlighting
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;修改&lt;strong&gt;~/.zshrc&lt;/strong&gt;，找到設定檔中&lt;code class=&quot;highlighter-rouge&quot;&gt;plugins=(git)&lt;/code&gt;的部分，將之修改成以下&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;c&quot;&gt;# If you had installed zsh-autosuggestions&lt;/span&gt;
 &lt;span class=&quot;nv&quot;&gt;plugins&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=(&lt;/span&gt;
     git
     zsh-autosuggestions
     zsh-syntax-highlighting
 &lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
 &lt;span class=&quot;c&quot;&gt;# If you only want to install zsh-syntax-highlighting&lt;/span&gt;
 &lt;span class=&quot;nv&quot;&gt;plugins&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=(&lt;/span&gt;
     git
     zsh-syntax-highlighting
 &lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;重新載入zsh&lt;/p&gt;

    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; ~/.zshrc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;tools&quot;&gt;Tools&lt;/h2&gt;

&lt;h3 id=&quot;fzf&quot;&gt;fzf&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/junegunn/fzf&quot;&gt;fzf&lt;/a&gt;是一個命令列的工具，使你可以fuzzy search你之前下過的指令或者是當前目錄底下的檔案，詳細的使用情形可以參考&lt;a href=&quot;https://www.youtube.com/watch?v=qgG5Jhi_Els&quot;&gt;這個影片&lt;/a&gt;，其安裝方式如下&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone &lt;span class=&quot;nt&quot;&gt;--depth&lt;/span&gt; 1 https://github.com/junegunn/fzf.git ~/.fzf
~/.fzf/install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在安裝完成了以後，可以隨時在命令列按下&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;Ctrl+R&amp;gt;&lt;/code&gt;來搜尋之前下過的指令、按下&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;Ctrl+T&amp;gt;&lt;/code&gt;來搜尋當前目錄底下的檔案，這個工具好用的地方是，在搜尋的時候並不需要打上完全一樣的字串，只需要打上相似的字串就可以直接幫你動態地尋找指令和命令了。&lt;/p&gt;

&lt;h3 id=&quot;hadoop-bash-completion&quot;&gt;hadoop-bash-completion&lt;/h3&gt;

&lt;p&gt;當你需要在命令列上面操作一些在hadoop filesystem上面的檔案的時候，你可能會希望hadoop也可以支援像一般bash的路徑自動完成的功能，這時你可以參考&lt;a href=&quot;https://github.com/lensesio/hadoop-bash-completion&quot;&gt;hadoop-bash-completion&lt;/a&gt;，使用的方法很簡單，只需要將repo裡面的&lt;a href=&quot;https://github.com/lensesio/hadoop-bash-completion/blob/master/hadoop-completion.sh&quot;&gt;hadoop-completion.sh&lt;/a&gt;下載下來，並source它就行了&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;source &lt;/span&gt;hadoop-completion.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;之後每當你打上hadoop相關指令或是路徑的時候，按下&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;tab&amp;gt;&lt;/code&gt;就會自動完成了。&lt;/p&gt;

&lt;h2 id=&quot;參考資料&quot;&gt;參考資料&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://dustinhsiao21.com/2019/04/09/%E9%80%8F%E9%81%8E%E5%9C%A8-mac-%E4%B8%8A%E5%AE%89%E8%A3%9Diterm2-%E6%B4%BB%E6%BD%91%E4%BD%A0%E7%9A%84%E7%B5%82%E7%AB%AF%E6%A9%9F/&quot;&gt;透過在 Mac 上安裝iTerm2 活潑你的終端機&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Your Name</name></author><category term="Tool" /><summary type="html">這篇記錄一下我在terminal裡面常使用的一些小工具們。</summary></entry><entry><title type="html">Deep contextualized word representation</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/23/deep-contextualized-word-representation/" rel="alternate" type="text/html" title="Deep contextualized word representation" /><published>2020-03-23T00:00:00+00:00</published><updated>2020-03-23T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/23/deep-contextualized-word-representation</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/23/deep-contextualized-word-representation/">&lt;p&gt;這篇簡單介紹一下赫赫有名的ELMo，其源自於&lt;a href=&quot;https://www.aclweb.org/anthology/N18-1202.pdf&quot;&gt;Deep contextualized word representation&lt;/a&gt;這篇paper。
&lt;!--more--&gt;&lt;/p&gt;

&lt;h2 id=&quot;簡介&quot;&gt;簡介&lt;/h2&gt;

&lt;p&gt;在做許許多多NLP任務的時候，我們通常都會將輸入進來的字轉換成word embedding，而一個好的embedding可以使整個任務的成效更好，而這篇paper的目的就是想要去尋找好的embedding。&lt;/p&gt;

&lt;h2 id=&quot;方法&quot;&gt;方法&lt;/h2&gt;

&lt;h3 id=&quot;bidirectional-language-model&quot;&gt;Bidirectional Language Model&lt;/h3&gt;

&lt;p&gt;其主要的模型架構還蠻簡單的，就是多層的bidirectional language model。&lt;/p&gt;

&lt;p&gt;假定我們輸入一個序列&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;N=(t_1, t_2, ..., t_N)&lt;/script&gt;

&lt;p&gt;一個forward laguage model做的事情就是在給定序列的前半部&lt;script type=&quot;math/tex&quot;&gt;(t_1, t_2, ..., t_{k-1})&lt;/script&gt;，去讓&lt;script type=&quot;math/tex&quot;&gt;t_k&lt;/script&gt;被產生出來的機率可以最大，其主要的objective function如下&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(t_1, t_2, ..., t_N)=\prod \limits_{k=1}\limits^{N}p(t_k\vert t_1, t_2, ..., t_{k-1})&lt;/script&gt;

&lt;p&gt;而backward language model做的事情跟forward language model差不多，就只是將序列反著輸入進去&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(t_1, t_2, ..., t_N)=\prod \limits_{k=1}\limits^{N}p(t+k\vert t_{k+1}, t_{k+2}, ..., t_N)&lt;/script&gt;

&lt;p&gt;Birirectional language model就是將forward language model和backward language model合在一起做訓練&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum\limits_{k=1}\limits^{N}\left( \log p(t_k\vert t_1, ..., t_{k-1};\overrightarrow{\theta_{LSTM}}) + \log p(t_k\vert t_{k+1}, ..., t_N;\overleftarrow{\theta_{LSTM}}) \right)&lt;/script&gt;

&lt;h3 id=&quot;elmo&quot;&gt;ELMo&lt;/h3&gt;

&lt;p&gt;前面我們訓練多層的bidirectional language model，在每個輸入進來的token &lt;script type=&quot;math/tex&quot;&gt;t_k&lt;/script&gt;得到了很多embedding，那我們應該要用怎麼樣的方式來使用呢？這篇paper建議將這些embedding做weighted sum，而其中的weight是根據後面要解決的NLP任務來決定的。&lt;/p&gt;

&lt;p&gt;假如果們訓練了&lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;層bidirectional language model，我們對於每一個token &lt;script type=&quot;math/tex&quot;&gt;t_k&lt;/script&gt;可以得到&lt;script type=&quot;math/tex&quot;&gt;2L+1&lt;/script&gt;個embedding&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R_k=\left\{ x_k^{LM}, \overrightarrow{h_{k,j}^{LM}}, \overleftarrow{h_{k,j}^{LM}}\vert j=1, ..., L \right\}\\=\left\{ h_{k,j}^{LM}\vert j=0, ..., L \right\}&lt;/script&gt;

&lt;p&gt;這&lt;script type=&quot;math/tex&quot;&gt;2L+1&lt;/script&gt;個embedding包含了token一開始進來經過linear transform的embedding &lt;script type=&quot;math/tex&quot;&gt;x^{LM}_k&lt;/script&gt;，以及&lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;層forward/backward language model的hidden state&lt;script type=&quot;math/tex&quot;&gt;\{ \overrightarrow{h_{k,j}^{LM}}, \overleftarrow{h_{k,j}^{LM}} \}&lt;/script&gt;，而ELMo會將這&lt;script type=&quot;math/tex&quot;&gt;2L+1&lt;/script&gt;個embedding融合成一個&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathrm{ELMo}^{task}_k=E(R_k;\theta^{task})=\gamma^{task}\sum\limits_{j=0}\limits^{L}s_j^{task}h_{k,j}^{LM}&lt;/script&gt;

&lt;p&gt;其中&lt;script type=&quot;math/tex&quot;&gt;s^{task}_j&lt;/script&gt;是經過&lt;script type=&quot;math/tex&quot;&gt;\mathrm{softmax}&lt;/script&gt;標準化的weight，而&lt;script type=&quot;math/tex&quot;&gt;\gamma^{task}&lt;/script&gt;的目的是讓後面NLP的任務可以自行決定要如何去scale這整個向量。&lt;/p&gt;

&lt;h2 id=&quot;實驗&quot;&gt;實驗&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;experiments.png&quot; alt=&quot;Experiments&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以從上表中看到，使用了ELMo的embedding以後，成效就起飛了。&lt;/p&gt;

&lt;h2 id=&quot;結論&quot;&gt;結論&lt;/h2&gt;

&lt;p&gt;ELMo是個我覺得架構還蠻算簡單的，製作word embedding的方式，也可以根據你後面想要解決的NLP task做fine-tuned。&lt;/p&gt;</content><author><name>Your Name</name></author><category term="Paper" /><summary type="html">這篇簡單介紹一下赫赫有名的ELMo，其源自於Deep contextualized word representation這篇paper。</summary></entry><entry><title type="html">Attention Is All You Need</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/21/attention-is-all-you-need/" rel="alternate" type="text/html" title="Attention Is All You Need" /><published>2020-03-21T00:00:00+00:00</published><updated>2020-03-21T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/21/attention-is-all-you-need</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/21/attention-is-all-you-need/">&lt;p&gt;這篇文章想要簡介一下被廣泛使用的Transformer是什麼。&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;簡介&quot;&gt;簡介&lt;/h2&gt;

&lt;p&gt;在以前處理有關sequence的問題，像是文字、語音和影像等，所使用的model不是CNN就是RNN，然而它們各自有一些缺點，像是CNN必須要疊的很深才可以看到比較長範圍的資訊，RNN比較不能應付較長的序列，並且必須sequential的做訓練，不能夠被平行化，而這篇paper提出了另一個一樣能套用在sequence上的model，稱之為Transformer。&lt;/p&gt;

&lt;h2 id=&quot;方法&quot;&gt;方法&lt;/h2&gt;

&lt;p&gt;底下的圖是paper當中所提出的Transformer的架構，跟一般做language translation的架構蠻像的，由encoder和decoder組成，但可以看到其中有一個比較特別的layer：Multi-Head Attention。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;transformer-architecture.png&quot; alt=&quot;Transformer model architecture&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;scaled-dot-product-attention&quot;&gt;Scaled Dot-Product Attention&lt;/h3&gt;

&lt;p&gt;在講Multi-Head Attention Layer之前，得先要講一下Scaled Dot-Product Attention，因為Multi-Head Attention Layer其實是由Scaled Dot-Product Attention所組成的，而下圖為Scaled Dot-Product Attention的架構。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;scaled-dot-product-attention.png&quot; alt=&quot;Scaled Dot-Product Attention&quot; /&gt;&lt;/p&gt;

&lt;p&gt;假設我們現在有一個sequence input &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{x}&lt;/script&gt;，其長度為&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt;，而每一個元&lt;script type=&quot;math/tex&quot;&gt;x_i&lt;/script&gt;是一個&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt;維度的向量，可以想像成是我們已經把一個輸入進來的句子轉換成了&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt;維的word embeddings&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol{x}=[x_1, x_2, ..., x_n],\ x_i\in\mathbb{R}^d&lt;/script&gt;

&lt;p&gt;而圖中的&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{Q}&lt;/script&gt;、&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{K}&lt;/script&gt;、&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{V}&lt;/script&gt;，分別代表的是Query、Key、Value，是由不同的weight各自乘上輸入&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{x}&lt;/script&gt;所得到的&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol{Q}=[Q_1, Q_2, ..., Q_n],\ Q_i=W_Qx_i\in\mathbb{R}^{d_k}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol{K}=[K_1, K_2, ..., K_n],\ K_i=W_Kx_i\in\mathbb{R}^{d_k}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol{V}=[V_1, V_2, ..., V_n],\ V_i=W_Vx_i\in\mathbb{R}^{d_v}&lt;/script&gt;

&lt;p&gt;Scaled Dot-Product Attention做的事情就是，對每個時間點&lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;，用其Query對所有時間點的Key做內積，scale以後過&lt;script type=&quot;math/tex&quot;&gt;\mathrm{softmax}&lt;/script&gt;得到attention weight，再與Value做weighted sum。假設我們想要得到&lt;script type=&quot;math/tex&quot;&gt;t=1&lt;/script&gt;的輸出，其流程大概會是底下這樣&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;取出&lt;script type=&quot;math/tex&quot;&gt;t=1&lt;/script&gt;的query &lt;script type=&quot;math/tex&quot;&gt;Q_1&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;對所有時間點的key做內積，得到原始的attention weight &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{a}=[Q_1K_1, Q_1K_2, ..., Q_1K_n], Q_iK_j \in \mathbb{R}&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;對原始的attention weight除上維度開根號，以避免原始值太大，亦即&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{a}=\frac{\boldsymbol{a}}{\sqrt{d_k}}&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;將&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{a}&lt;/script&gt;通過&lt;script type=&quot;math/tex&quot;&gt;\mathrm{softmax}&lt;/script&gt;，得到最終的attention weight &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{\hat a}=[\hat a_1, \hat a_2, ..., \hat a_n], \hat a_i\in\mathbb{R}&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;利用attention weight對value做weighted sum，得到時間點&lt;script type=&quot;math/tex&quot;&gt;t=1&lt;/script&gt;的輸出&lt;script type=&quot;math/tex&quot;&gt;z_1&lt;/script&gt;&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;z_1=V_1*\hat a_1+V_2*\hat a_2+...+V_n*\hat a_n\in\mathbb{R}^{d_v}&lt;/script&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;其他時間點的輸出&lt;script type=&quot;math/tex&quot;&gt;z_2, ..., z_n&lt;/script&gt;都是利用相同的方式得到的，我們也可以從中發現到，其實產生某個特定時間點的輸出&lt;script type=&quot;math/tex&quot;&gt;z_t&lt;/script&gt;並沒有與其他時間點有關聯，我們可以簡單地用矩陣相乘的方式一次算出所有的輸出&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol{z}=[z_1, z_2, ..., z_n]=\mathrm{Attention}(\boldsymbol{Q}, \boldsymbol{K}, \boldsymbol{V})=\boldsymbol{V}\left(\mathrm{softmax}(\frac{\boldsymbol{Q}^T\boldsymbol{K}}{\sqrt{d_k}})\right)^T&lt;/script&gt;

&lt;p&gt;至此我們有了可以輸入一個序列&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{x}&lt;/script&gt;，得到與&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{x}&lt;/script&gt;相同長度輸出&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{z}&lt;/script&gt;的Scaled Dot-Product Attention layer。&lt;/p&gt;

&lt;h3 id=&quot;multi-head-attention-layer&quot;&gt;Multi-Head Attention Layer&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;multi-head-attention.png&quot; alt=&quot;Multi-Head Attention&quot; /&gt;&lt;/p&gt;

&lt;p&gt;而在Transformer架構中的Multi-Head Attention其實就是把輸入的&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{Q}&lt;/script&gt;、&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{K}&lt;/script&gt;、&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{V}&lt;/script&gt;過linear transform、把多個Scaled Dot-Product Attention平行的疊在一起、將每個輸出都接起來後再過一個linear transform&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathrm{MultiHead}(\boldsymbol{Q}, \boldsymbol{K}, \boldsymbol{V})=\mathrm{Concat}(\mathrm{head_1}, ..., \mathrm{head_h})W^O&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathrm{head_i}=\mathrm{Attention}(\boldsymbol{Q}W_i^Q, \boldsymbol{K}W_i^K, \boldsymbol{V}W_i^V)\\W_i^Q\in\mathbb{R}^{d_{model}\times d_{k}}, W_i^K\in\mathbb{R}^{d_{model}\times d_k}, W_i^V\in\mathbb{R}^{d_{model}\times d_v}&lt;/script&gt;

&lt;p&gt;在paper裡面，將&lt;script type=&quot;math/tex&quot;&gt;\mathrm{head}&lt;/script&gt;的個數設為&lt;script type=&quot;math/tex&quot;&gt;h=8&lt;/script&gt;、&lt;script type=&quot;math/tex&quot;&gt;d_k=d_v=d_{model}/h=64&lt;/script&gt;，其中的&lt;script type=&quot;math/tex&quot;&gt;d_{model}&lt;/script&gt;是Multi-Head Attention輸出的維度。&lt;/p&gt;

&lt;h3 id=&quot;add--norm&quot;&gt;Add &amp;amp; Norm&lt;/h3&gt;

&lt;p&gt;這一層做的事情是加一個residual connection，並做&lt;a href=&quot;https://arxiv.org/pdf/1607.06450.pdf&quot;&gt;Layer Normalization&lt;/a&gt;。&lt;/p&gt;

&lt;h3 id=&quot;positional-encoding&quot;&gt;Positional Encoding&lt;/h3&gt;

&lt;p&gt;在上面的方法中，在產生特定時間點輸出的時候，並不會對比較近或比較遠的輸入而有不一樣的操作，使得在產生&lt;script type=&quot;math/tex&quot;&gt;z_3&lt;/script&gt;的時候，model並不知道&lt;script type=&quot;math/tex&quot;&gt;x_1&lt;/script&gt;是比較近而&lt;script type=&quot;math/tex&quot;&gt;x_{10}&lt;/script&gt;是比較遠的，因此在paper裡對輸入都加入了positional encoding，好讓model可以看輸入就知道這個輸入是哪一個時間點的輸入。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;PE(pos, 2i)=\sin(pos/10000^{2i/d_{model}})\\PE(pos, 2i+1)=\cos(pos/10000^{2i/d_{model}})&lt;/script&gt;

&lt;h3 id=&quot;encoding--decoding-動畫&quot;&gt;Encoding / Decoding 動畫&lt;/h3&gt;

&lt;p&gt;底下是從&lt;a href=&quot;https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html&quot;&gt;Google AI Blog&lt;/a&gt;中擷取下來的動畫，解釋了Transformer在encoding和decoding時的流程。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://3.bp.blogspot.com/-aZ3zvPiCoXM/WaiKQO7KRnI/AAAAAAAAB_8/7a1CYjp40nUg4lKpW7covGZJQAySxlg8QCLcBGAs/s640/transform20fps.gif&quot; alt=&quot;Transformer process&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;實驗&quot;&gt;實驗&lt;/h2&gt;

&lt;p&gt;Paper將Transformer應用在翻譯上，可以看到Transformer的表現超群。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;translation-results.png&quot; alt=&quot;Translation Results&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;結論&quot;&gt;結論&lt;/h2&gt;

&lt;p&gt;這篇paper提出了Transformer的架構，底層使用了Multi-Head Attention，是一個與CNN、RNN一樣，可以輸入輸出都是序列的layer，當你也有要處理序列的問題時，不妨試試看，或許可以有不錯的表現。&lt;/p&gt;</content><author><name>Your Name</name></author><category term="Paper" /><summary type="html">這篇文章想要簡介一下被廣泛使用的Transformer是什麼。</summary></entry><entry><title type="html">Vim Plugins</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/09/vim-plugins/" rel="alternate" type="text/html" title="Vim Plugins" /><published>2020-03-09T00:00:00+00:00</published><updated>2020-03-09T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/09/vim-plugins</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/09/vim-plugins/">&lt;p&gt;這邊記錄一下我目前所使用的Vim plugin以及它們的功能。
&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;市面上有很多Integrated Development Environment (IDE)來幫助你開發，像是&lt;a href=&quot;https://developer.apple.com/xcode/&quot;&gt;Xcode&lt;/a&gt;、&lt;a href=&quot;https://visualstudio.microsoft.com/zh-hant/&quot;&gt;Visual Studio&lt;/a&gt;、&lt;a href=&quot;https://www.jetbrains.com/idea/&quot;&gt;Intellij&lt;/a&gt;、&lt;a href=&quot;https://www.jetbrains.com/pycharm/&quot;&gt;Pycharm&lt;/a&gt;、&lt;a href=&quot;https://www.sublimetext.com/&quot;&gt;Sublime&lt;/a&gt;等等，然而在終端機上的文字編輯器，應該大多都是用vim來開發，而vim本身也有很多神人開發的套件，讓你可以在vim裡面做到像上面IDE一樣的操作，底下介紹一下我目前所使用的一些套件。&lt;/p&gt;

&lt;p&gt;目前我所使用的設定檔，原先是來自於&lt;a href=&quot;https://github.com/timss/vimconf&quot;&gt;timss/vimconf&lt;/a&gt;，看star數也蠻多人推薦&lt;a href=&quot;https://github.com/amix/vimrc&quot;&gt;amix/vimrc&lt;/a&gt;，你也可以去網路上找你心目中所屬的設定檔。&lt;/p&gt;

&lt;h2 id=&quot;vundle&quot;&gt;Vundle&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/VundleVim/Vundle.vim&quot;&gt;Vundle&lt;/a&gt;是一個vim套件的管理工具，使你可以直接打上vim plugin repo的名字就能安裝至你的vim上，像是&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Plug &lt;span class=&quot;s1&quot;&gt;'gmarik/Vundle.vim'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在宣告好想要安裝的套件以後，打開vim，再打上&lt;code class=&quot;highlighter-rouge&quot;&gt;:PlugInstall&lt;/code&gt;就會將宣告的套件安裝在&lt;strong&gt;[user name]/.vim/bundle&lt;/strong&gt;裡面。如果想要移除某個套件，只需要在設定檔將套件的宣告移除，並在vim裡面打上&lt;code class=&quot;highlighter-rouge&quot;&gt;:PlugClean&lt;/code&gt;，相當的方便。&lt;/p&gt;

&lt;h2 id=&quot;plugins&quot;&gt;Plugins&lt;/h2&gt;

&lt;p&gt;接下來介紹一下我覺得好像不錯用的套件們，大多的套件只需要像底下這樣宣告，並且&lt;code class=&quot;highlighter-rouge&quot;&gt;:PlugInstall&lt;/code&gt;就能安裝完成了。&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Plug &lt;span class=&quot;s1&quot;&gt;'[plugin name]'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;ervandewsupertab&quot;&gt;&lt;a href=&quot;https://github.com/ervandew/supertab&quot;&gt;ervandew/supertab&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;一個可以讓你用tab自動完成各種東西的套件，可以用tab完成function、variable等等。&lt;/p&gt;

&lt;h3 id=&quot;ycm-coreyoucompleteme&quot;&gt;&lt;a href=&quot;https://github.com/ycm-core/YouCompleteMe&quot;&gt;ycm-core/YouCompleteMe&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;也是一個自動完成各種東西的套件，只是安裝起來沒有像supertab那樣簡單，不僅需要宣告在設定檔裡，還需要安裝其他程式語言，像是go、nodejs等，詳細的安裝流程可以參考官方的GitHub。&lt;/p&gt;

&lt;p&gt;我會在設定檔裡面多加底下的設定，使你可以按下enter就可以選擇自動完成的東西(預設好像是按&lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + y&lt;/code&gt;)，另一個設定是讓你能用&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;Leader&amp;gt;g&lt;/code&gt;跳到function定義的部分。&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if &lt;/span&gt;exists&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'g:plugs[&quot;YouCompleteMe&quot;]'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;let &lt;/span&gt;g:ycm_autoclose_preview_window_after_completion&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1
    &lt;span class=&quot;nb&quot;&gt;let &lt;/span&gt;g:ycm_key_list_stop_completion &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'&amp;lt;C-y&amp;gt;'&lt;/span&gt;, &lt;span class=&quot;s1&quot;&gt;'&amp;lt;CR&amp;gt;'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
    nnoremap &amp;lt;Leader&amp;gt;g :YcmCompleter GoToDefinitionElseDeclaration&amp;lt;CR&amp;gt;
endif
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;itchynylightlinevim&quot;&gt;&lt;a href=&quot;https://github.com/itchyny/lightline.vim&quot;&gt;itchyny/lightline.vim&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;讓vim可以有status bar，讓你知道現在是處理什麼樣的檔案、在Normal mode、Visual mode還是Insert mode等。&lt;/p&gt;

&lt;h3 id=&quot;blingvim-bufferline&quot;&gt;&lt;a href=&quot;https://github.com/bling/vim-bufferline&quot;&gt;bling/vim-bufferline&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;在status bar裡面顯示目前開啟的所有檔案。&lt;/p&gt;

&lt;h3 id=&quot;mbbillundotree&quot;&gt;&lt;a href=&quot;https://github.com/mbbill/undotree&quot;&gt;mbbill/undotree&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;undotree會紀錄你對這個檔案的操作，使你可以隨時退回先前的版本，有點像簡易版的git。&lt;/p&gt;

&lt;h3 id=&quot;nanotechjellybeansvim&quot;&gt;&lt;a href=&quot;https://github.com/nanotech/jellybeans.vim&quot;&gt;nanotech/jellybeans.vim&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;vim的color schema。&lt;/p&gt;

&lt;h3 id=&quot;tomtomtcomment_vim&quot;&gt;&lt;a href=&quot;https://github.com/tomtom/tcomment_vim&quot;&gt;tomtom/tcomment_vim&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;幫助你快速將程式碼comment起來的套件，在Visual mode選定好區塊以後，打上&lt;code class=&quot;highlighter-rouge&quot;&gt;:gc&lt;/code&gt;便能將選取的區塊都comment起來，更多的使用方法可以參考上方連結裡面的文件。&lt;/p&gt;

&lt;h3 id=&quot;sominivim-autoclose&quot;&gt;&lt;a href=&quot;https://github.com/Townk/vim-autoclose&quot;&gt;somini/vim-autoclose&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;自動幫你將括號或是其他該成雙成對的東西補齊的套件。&lt;/p&gt;

&lt;h3 id=&quot;tpopevim-eunuch&quot;&gt;&lt;a href=&quot;https://github.com/tpope/vim-eunuch&quot;&gt;tpope/vim-eunuch&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;讓你能在vim裡面直接使用Unix指令的套件，像是&lt;code class=&quot;highlighter-rouge&quot;&gt;:SudoEdit&lt;/code&gt;、&lt;code class=&quot;highlighter-rouge&quot;&gt;:Rename&lt;/code&gt;等等，詳細的指令可以參考上方連結。&lt;/p&gt;

&lt;h3 id=&quot;tpopevim-fugitive&quot;&gt;&lt;a href=&quot;https://github.com/tpope/vim-fugitive&quot;&gt;tpope/vim-fugitive&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;讓你能在vim裡面直接操作git指令的套件。&lt;/p&gt;

&lt;h3 id=&quot;tpopevim-surround&quot;&gt;&lt;a href=&quot;https://github.com/tpope/vim-surround&quot;&gt;tpope/vim-surround&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;使你可以快速改變括號的套件，像是將&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&quot;Hello world!&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;迅速改成&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;'Hello world!'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;更多的指令請參考上面連結。&lt;/p&gt;

&lt;h3 id=&quot;junegunnvim-easy-align&quot;&gt;&lt;a href=&quot;https://github.com/junegunn/vim-easy-align&quot;&gt;junegunn/vim-easy-align&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;能迅速將&lt;code class=&quot;highlighter-rouge&quot;&gt;=&lt;/code&gt;對齊的套件。&lt;/p&gt;

&lt;h3 id=&quot;honzavim-snippets--sirverultisnips&quot;&gt;&lt;a href=&quot;https://github.com/honza/vim-snippets&quot;&gt;honza/vim-snippets&lt;/a&gt; / &lt;a href=&quot;https://github.com/SirVer/ultisnips&quot;&gt;sirver/ultisnips&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;能快速補齊程式碼的套件，像是打上&lt;code class=&quot;highlighter-rouge&quot;&gt;def test[tab]&lt;/code&gt;就會自動幫你將function的架構打出來。&lt;/p&gt;

&lt;h3 id=&quot;mhinzvim-startify&quot;&gt;&lt;a href=&quot;https://github.com/mhinz/vim-startify&quot;&gt;mhinz/vim-startify&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;一個好看的vim開始畫面。&lt;/p&gt;

&lt;h3 id=&quot;mhinzvim-signify&quot;&gt;&lt;a href=&quot;https://github.com/mhinz/vim-signify&quot;&gt;mhinz/vim-signify&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;顯示檔案裡面有哪些部分與git上的有所差異。&lt;/p&gt;

&lt;h3 id=&quot;vim-syntasticsyntastic&quot;&gt;&lt;a href=&quot;https://github.com/vim-syntastic/syntastic&quot;&gt;vim-syntastic/syntastic&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;幫你做語法檢查的套件，我自己會加上底下這行，令&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;Leader&amp;gt;c&lt;/code&gt;當作快捷鍵。&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;noremap &amp;lt;silent&amp;gt;&amp;lt;Leader&amp;gt;c  :SyntasticCheck&amp;lt;CR&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;majutsushitagbar&quot;&gt;&lt;a href=&quot;https://github.com/majutsushi/tagbar&quot;&gt;majutsushi/tagbar&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;當你有使用ctags或cscope先對目錄底下的程式碼先做索引的話，可以使用tagbar在vim裡面顯示所有的tag。&lt;/p&gt;

&lt;h3 id=&quot;mileszsackvim&quot;&gt;&lt;a href=&quot;https://github.com/mileszs/ack.vim&quot;&gt;mileszs/ack.vim&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;在vim裡面使用grep或是ag(&lt;a href=&quot;https://github.com/ggreer/the_silver_searcher&quot;&gt;The Silver Searcher&lt;/a&gt;)來搜尋特定字詞的套件，我自己會放以下的設定來建立快捷鍵，打上&lt;code class=&quot;highlighter-rouge&quot;&gt;ack[space]&lt;/code&gt;會自動替換成&lt;code class=&quot;highlighter-rouge&quot;&gt;Ack!&lt;/code&gt;，在Normal mode中打上&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;Leader&amp;gt;a&lt;/code&gt;會去搜尋游標當下所在的字詞。&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if &lt;/span&gt;executable&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'ag'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;let &lt;/span&gt;g:ackprg &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ag --vimgrep'&lt;/span&gt;
endif
cnoreabbrev ack Ack!
nnoremap &amp;lt;Leader&amp;gt;a :Ack!&amp;lt;CR&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;scrooloosenerdtree&quot;&gt;&lt;a href=&quot;https://github.com/preservim/nerdtree&quot;&gt;scrooloose/nerdtree&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;樹狀的檔案瀏覽器。&lt;/p&gt;

&lt;h3 id=&quot;ctrlpvimctrlpvim&quot;&gt;&lt;a href=&quot;https://github.com/kien/ctrlp.vim&quot;&gt;ctrlpvim/ctrlp.vim&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;使你可以在vim裡面打上&lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + p&lt;/code&gt;便能搜尋目錄底下的檔案名稱。&lt;/p&gt;

&lt;h3 id=&quot;junegunnfzf--junegunnfzfvim&quot;&gt;&lt;a href=&quot;https://github.com/junegunn/fzf&quot;&gt;junegunn/fzf&lt;/a&gt; / &lt;a href=&quot;https://github.com/junegunn/fzf.vim&quot;&gt;junegunn/fzf.vim&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;功能與上面的&lt;strong&gt;ctrlpvim/ctrlp.vim&lt;/strong&gt;幾乎雷同，只是底層是用fzf來做搜尋，我個人比較偏好這個套件，需要使用底下的設定來複寫&lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + p&lt;/code&gt;的預設快捷鍵。&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if &lt;/span&gt;exists&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'g:plugs[&quot;fzf.vim&quot;]'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    nmap &amp;lt;c-p&amp;gt; :FZF&amp;lt;CR&amp;gt;
endif
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;terrymavim-expand-region&quot;&gt;&lt;a href=&quot;https://github.com/terryma/vim-expand-region&quot;&gt;terryma/vim-expand-region&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;讓你可以透過&lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;_&lt;/code&gt;來簡單的擴大或縮小選取的範圍，可以看連結內的demo。&lt;/p&gt;

&lt;h3 id=&quot;godlygeektabular&quot;&gt;&lt;a href=&quot;https://github.com/godlygeek/tabular&quot;&gt;godlygeek/tabular&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;讓你可以方便的對齊你的程式碼，可以看這邊的&lt;a href=&quot;http://vimcasts.org/episodes/aligning-text-with-tabular-vim/&quot;&gt;demo&lt;/a&gt;，我自己會加上底下的設定來建立快捷鍵。&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if &lt;/span&gt;exists&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'g:plugs[&quot;tabular&quot;]'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    cnoreabbrev tab Tab
endif
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;terrymavim-multiple-cursors&quot;&gt;&lt;a href=&quot;https://github.com/terryma/vim-multiple-cursors&quot;&gt;terryma/vim-multiple-cursors&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;讓vim擁有像Sublime那樣的多個游標的功能。&lt;/p&gt;

&lt;h3 id=&quot;roxmavim-paste-easy&quot;&gt;&lt;a href=&quot;https://github.com/roxma/vim-paste-easy&quot;&gt;roxma/vim-paste-easy&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;在電腦上複製程式碼，想直接貼到vim裡面的時候有可能會有格式跑掉的問題，這個套件可以幫你自動在貼上前&lt;code class=&quot;highlighter-rouge&quot;&gt;set paste&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;更多資訊可以參考上面附的GitHub連結或是&lt;a href=&quot;https://vimawesome.com/plugin/vim-paste-easy&quot;&gt;這裡&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;tips&quot;&gt;Tips&lt;/h2&gt;

&lt;p&gt;紀錄一下常用到的快捷鍵。&lt;/p&gt;

&lt;h3 id=&quot;查看現在所開啟檔案的相對絕對路徑&quot;&gt;查看現在所開啟檔案的相對/絕對路徑&lt;/h3&gt;

&lt;p&gt;想要查看檔案的相對路徑時，可以按下&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;Ctrl-G&amp;gt;&lt;/code&gt;，但過不久就會消失。&lt;/p&gt;

&lt;p&gt;若是想要看絕對路徑的話，按下&lt;code class=&quot;highlighter-rouge&quot;&gt;1 &amp;lt;Ctrl-G&amp;gt;&lt;/code&gt;，vim會等你按下enter以後再把路徑隱藏。&lt;/p&gt;</content><author><name>Your Name</name></author><category term="Tool" /><summary type="html">這邊記錄一下我目前所使用的Vim plugin以及它們的功能。</summary></entry><entry><title type="html">Gradient Descent和Learning Rate</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/07/gradient-descent-and-learning-rate/" rel="alternate" type="text/html" title="Gradient Descent和Learning Rate" /><published>2020-03-07T00:00:00+00:00</published><updated>2020-03-07T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/07/gradient-descent-and-learning-rate</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/07/gradient-descent-and-learning-rate/">&lt;p&gt;稍微講一下Machine Learning當中經常被使用的gradient descent的概念以及調整learning rate的方法。&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;gradient-descent的概念&quot;&gt;Gradient Descent的概念&lt;/h2&gt;

&lt;p&gt;在各種Machine Learning的paper當中，常可以看到作者們都說他們是用gradient descent來找到model的參數，那gradient descent是什麼呢？&lt;/p&gt;

&lt;p&gt;假如我們今天的loss function是一個二次函數&lt;script type=&quot;math/tex&quot;&gt;\mathcal{L}(x)=x^2&lt;/script&gt;，其中&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;可以想作是model的參數，而我們的目標是希望找到一個&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;可以讓loss function可以最小。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;x-square.png&quot; alt=&quot;x square&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在訓練一開始的時候，我們會隨機產生model的參數，假設我們這次產生的參數為6，也就是&lt;script type=&quot;math/tex&quot;&gt;x=6&lt;/script&gt;，這時所得到的loss為&lt;script type=&quot;math/tex&quot;&gt;\mathcal{L}(6)=36&lt;/script&gt;，我們希望能調整一下參數&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;來讓loss下降一些，而使用的方法便是對loss function做微分，來得到目前在這個位置(&lt;script type=&quot;math/tex&quot;&gt;x=6&lt;/script&gt;)，loss function的趨勢是往哪邊走。&lt;/p&gt;

&lt;p&gt;對loss function微分並帶入現在的位置我們可以得到&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}'(x)=2x,\ \mathcal{L}'(6)=12&lt;/script&gt;

&lt;p&gt;意思是在&lt;script type=&quot;math/tex&quot;&gt;x=6&lt;/script&gt;的趨勢(斜率)是正的，當&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;增加的話，loss function的值也會隨之增加，反之便會減少，所以我們會將&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;去減掉其斜率來去尋找最小值，這時通常會再乘上一個人工設定的參數(learning rate) &lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt;，以避免一次更新參數的幅度過大，就變成了常見的gradient descent的公式&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x\leftarrow x-\alpha\bigtriangledown_x\mathcal{L}(x)&lt;/script&gt;

&lt;p&gt;假設我們這邊設定&lt;script type=&quot;math/tex&quot;&gt;\alpha=0.6&lt;/script&gt;，那經過一次更新以後，我們的參數就會變成&lt;script type=&quot;math/tex&quot;&gt;x=6-0.6*12=-1.2&lt;/script&gt;，再經過一次以後，參數會變成&lt;script type=&quot;math/tex&quot;&gt;x=-1.2-0.6*(-2.4)=0.24&lt;/script&gt;，隨著不斷的更新，參數也會越來越接近會讓loss function最小的&lt;script type=&quot;math/tex&quot;&gt;x=0&lt;/script&gt;。&lt;/p&gt;

&lt;p&gt;值得一提的是，這個人工設定的參數&lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt;其實是很重要的，有可能會決定這個model會不會收斂，舉例來說，假設現在&lt;script type=&quot;math/tex&quot;&gt;x=3&lt;/script&gt;且&lt;script type=&quot;math/tex&quot;&gt;\alpha=1&lt;/script&gt;，經過一次更新以後會得到&lt;script type=&quot;math/tex&quot;&gt;x=3-1*6=-3&lt;/script&gt;，再次更新會得到&lt;script type=&quot;math/tex&quot;&gt;x=-3-1*(-6)=3&lt;/script&gt;，使得參數不斷地在&lt;script type=&quot;math/tex&quot;&gt;3&lt;/script&gt;和&lt;script type=&quot;math/tex&quot;&gt;-3&lt;/script&gt;之間震盪，不會收斂到最小值0，所以底下將會介紹一些方法來適時的調整learning rate，讓model比較有機會可以收斂到最小值。&lt;/p&gt;

&lt;h2 id=&quot;learning-rate的調整&quot;&gt;Learning Rate的調整&lt;/h2&gt;

&lt;p&gt;底下的&lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;代表model的參數、&lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt;為learning rate、&lt;script type=&quot;math/tex&quot;&gt;\bigtriangledown_\theta&lt;/script&gt;是對model參數作微分、&lt;script type=&quot;math/tex&quot;&gt;\mathcal{L}_\theta(x)&lt;/script&gt;是指在model參數為&lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;的情況下，對model輸入&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;，loss function算出來的值。&lt;/p&gt;

&lt;h3 id=&quot;stochastic-gradient-descent&quot;&gt;Stochastic Gradient Descent&lt;/h3&gt;

&lt;p&gt;最一般的gradient descent，learning rate為人工設定的固定常數。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta\leftarrow\theta-\alpha \bigtriangledown_\theta \mathcal{L}_\theta(x)&lt;/script&gt;

&lt;p&gt;而之所以加上&lt;strong&gt;Stochastic&lt;/strong&gt;的關係是因為，在每次更新的時候是使用小批次(mini-batch)的方式，所以多了一些隨機的成份在裡面。&lt;/p&gt;

&lt;h3 id=&quot;momentum&quot;&gt;Momentum&lt;/h3&gt;

&lt;p&gt;Momentum的概念是保留前面所算出來的gradient，像是一個小球滾下山坡，並不會到一個凹槽就停住，會有從山坡上滾下所帶來的動能，而Stochastic Gradient Descent所算出來的gradient只與目前當下的參數有關，相比之下較容易卡進local minimum。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;v_t=\gamma v_{t-1}+\alpha\bigtriangledown_\theta\mathcal{L}_\theta(x)\\ \theta\leftarrow\theta-v_t&lt;/script&gt;

&lt;p&gt;這邊的&lt;script type=&quot;math/tex&quot;&gt;v_{t-1}&lt;/script&gt;可以想成是前面gradient的累積，而&lt;script type=&quot;math/tex&quot;&gt;\gamma&lt;/script&gt;是一個參數，通常會設成&lt;script type=&quot;math/tex&quot;&gt;0.9&lt;/script&gt;，讓動能(之前gradient的影響)隨著時間遞減。&lt;/p&gt;

&lt;h3 id=&quot;nesterov-accelerated-gradient-nag&quot;&gt;Nesterov Accelerated Gradient (NAG)&lt;/h3&gt;

&lt;p&gt;概念與Momentum相似，只是多預測了一步，來達到抄捷徑的效果。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;v_t=\gamma v_{t-1}+\alpha\bigtriangledown_\theta\mathcal{L}_{\theta-\gamma v_{t-1}}(x)\\ \theta\leftarrow\theta-v_t&lt;/script&gt;

&lt;p&gt;根據先前的gradient &lt;script type=&quot;math/tex&quot;&gt;v_{t-1}&lt;/script&gt;，我們可以預期model的參數&lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;應該會跑到&lt;script type=&quot;math/tex&quot;&gt;\theta-\gamma v_{t-1}&lt;/script&gt;附近的地方，而在&lt;script type=&quot;math/tex&quot;&gt;\theta-\gamma v_{t-1}&lt;/script&gt;會算出新的gradient，所以我們的目標應該直接設在&lt;strong&gt;”&lt;script type=&quot;math/tex&quot;&gt;\theta-\gamma v_{t-1}&lt;/script&gt;之後要去的位置”&lt;/strong&gt;，來加速訓練的速度。&lt;/p&gt;

&lt;h3 id=&quot;adagrad&quot;&gt;Adagrad&lt;/h3&gt;

&lt;p&gt;在前面的Momentum和Nesterov Accelerated Gradient都是設好固定的learning rate，然而在訓練的過程當中通常會希望剛開始訓練時的learning rate較大，到後面調降learning rate的來找到極值，而Adagrad就是想要去動態的調整learning rate，其中的Ada是指Adaptive的意思。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta\leftarrow\theta-\frac{\alpha}{\sqrt{G_t+\epsilon}}\bigtriangledown_\theta\mathcal{L}_\theta(x)&lt;/script&gt;

&lt;p&gt;上面的&lt;script type=&quot;math/tex&quot;&gt;G_t&lt;/script&gt;指的是從第一次update到現在所有gradient的平方和，而&lt;script type=&quot;math/tex&quot;&gt;\epsilon&lt;/script&gt;是避免除以0而加的一個常數，可以從式子看出來，剛開始的時候，累積的gradient很少，所以learning rate較大，而後gradient慢慢累積，learning rate就會減小了。&lt;/p&gt;

&lt;h3 id=&quot;adadelta&quot;&gt;Adadelta&lt;/h3&gt;

&lt;p&gt;雖說Adagrad可以動態的調整learning rate，但是其調整的方式只能不斷的減小，沒辦法在所有訓練的狀況下都有好的結果，而Adadelta就是想要來解決learning rate只能縮小的問題。&lt;/p&gt;

&lt;p&gt;在Adadelta的算法裡，它並不會把所有過去到現在的gradient都拿進來算平方和，而是用sliding window的方式取&lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt;個，並且在算平均時，是像Momentum那樣，使用decaying average&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E[g^2]_t=\gamma E[g^2]_{t-1}+(1-\gamma)g_t^2\\ \theta\leftarrow\theta-\frac{\alpha}{\sqrt{E[g^2]_t+\epsilon}}g_t&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;E[g^2]_t&lt;/script&gt;指的是到時間&lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;為止的gradient平方和，而&lt;script type=&quot;math/tex&quot;&gt;g_t&lt;/script&gt;是目前這個時間點&lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;的gradient，接著作者又稍微延伸了一下，試著不要設定learning rate &lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt;。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\triangle \theta_t=-\frac{RMS[\triangle\theta]_{t-1}}{RMS[g]_t}g_t\\ \theta_{t+1}=\theta_t+\triangle\theta_t&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;RMS&lt;/script&gt;是root, mean, square，也就是平方相加開根號，這個式子的概念可以想成，我這次的update幅度跟之前幾次的update幅度的平均的比值來當作learning rate。&lt;/p&gt;

&lt;h3 id=&quot;rmsprop&quot;&gt;RMSprop&lt;/h3&gt;

&lt;p&gt;RMSprop好像是同時期與Adadelta發展出來的，概念與Adadelta類似，可以說是Adadelta的一個特例。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta_{t+1}=\theta_t-\frac{\alpha}{\sqrt{E[g^2]_t+\epsilon}}g_t&lt;/script&gt;

&lt;h3 id=&quot;adaptive-moment-estimation-adam&quot;&gt;Adaptive Moment Estimation (Adam)&lt;/h3&gt;

&lt;p&gt;前面所介紹的Momentum會在計算參數更新時，考慮前一次更新的方向，而RMSprop會根據gradient的大小對learning rate進行調整，這邊的Adam則是兩者的集大成，將兩個東西合併在一起。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;m_t=\beta_1m_{t-1}+(1-\beta_1)g_t\\ v_t=\beta_2v_{t-1}+(1-\beta_2)g_t^2&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;m_t&lt;/script&gt;為Momentum的部分，&lt;script type=&quot;math/tex&quot;&gt;v_t&lt;/script&gt;為RMSprop的部分，而作者發現當&lt;script type=&quot;math/tex&quot;&gt;\beta_1&lt;/script&gt;和&lt;script type=&quot;math/tex&quot;&gt;\beta_2&lt;/script&gt;接近1的時候會有一些bias，所以有稍微修正一些&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat m_t=\frac{m_t}{1-\beta_1^t}\\ \hat v_t=\frac{v_t}{1-\beta_2^t}&lt;/script&gt;

&lt;p&gt;實際上更新的式子如下&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta_{t+1}=\theta_t-\frac{\alpha}{\sqrt{\hat v_t}+\epsilon}\hat m_t&lt;/script&gt;

&lt;h3 id=&quot;adamax&quot;&gt;Adamax&lt;/h3&gt;

&lt;p&gt;在前面Adam裡面，調整learning rate的時候是使用&lt;script type=&quot;math/tex&quot;&gt;\mathcal{l}_2-norm&lt;/script&gt;，而Adam的作者發現&lt;script type=&quot;math/tex&quot;&gt;\mathcal{l}_{\infty}-norm&lt;/script&gt;也蠻好用的，所以嘗試放在更新的式子中&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;u_t=\beta_2^\infty v_{t-1}+(1-\beta_2^\infty)\vert g_t\vert^\infty=\max(\beta_2\cdot v_{t-1},\vert g_t\vert)\\ \theta_{t+1}=\theta_t-\frac{\alpha}{u_t}\hat m_t&lt;/script&gt;

&lt;h3 id=&quot;nadam&quot;&gt;Nadam&lt;/h3&gt;

&lt;p&gt;Adam原先所使用的Mometum為最原始版本的，而Nadam便是使用NAG版本的Momentum，詳細的推倒和公式可以看考資料中的第二個連結。&lt;/p&gt;

&lt;h2 id=&quot;參考資料&quot;&gt;參考資料&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%B8%89-%E6%A2%AF%E5%BA%A6%E6%9C%80%E4%BD%B3%E8%A7%A3%E7%9B%B8%E9%97%9C%E7%AE%97%E6%B3%95-gradient-descent-optimization-algorithms-b61ed1478bd7&quot;&gt;機器/深度學習-基礎數學(三):梯度最佳解相關算法(gradient descent optimization algorithms)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ruder.io/optimizing-gradient-descent/index.html&quot;&gt;An overview of gradient descent optimization algorithms&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Your Name</name></author><category term="Machine-Learning" /><summary type="html">稍微講一下Machine Learning當中經常被使用的gradient descent的概念以及調整learning rate的方法。</summary></entry><entry><title type="html">Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/06/model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/" rel="alternate" type="text/html" title="Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks" /><published>2020-03-06T00:00:00+00:00</published><updated>2020-03-06T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/06/model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/06/model-agnostic-meta-learning-for-fast-adaptation-of-deep-networks/">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.03400.pdf&quot;&gt;這篇paper&lt;/a&gt;想要去尋找一個最佳的初始化參數，讓model可以在各個task上都可以得到不錯的表現。&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;簡介&quot;&gt;簡介&lt;/h2&gt;

&lt;p&gt;Meta learning可以說是一個讓model學習如何學習的方式，希望讓model知道如何學習是比較有效率的，如此一來便可以使model在比較少的資料仍可以得到不錯的效果。而這篇paper提出一個叫做MAML的方法，想要嘗試找到一個很好的初始化參數，讓model用少量資料在其他task上訓練的時候，不需要太多epoch就能獲得很好的效果。&lt;/p&gt;

&lt;h2 id=&quot;方法&quot;&gt;方法&lt;/h2&gt;

&lt;h3 id=&quot;task定義&quot;&gt;Task定義&lt;/h3&gt;

&lt;p&gt;先定義一下要被學習的task。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{T}= \{ \mathcal{L}(x_1, a_1, ..., x_H, a_H), q(x_1), q(x_{t+1}|x_t, a_t), H\}&lt;/script&gt;

&lt;p&gt;其中&lt;script type=&quot;math/tex&quot;&gt;\mathcal{L}&lt;/script&gt;是loss function，&lt;script type=&quot;math/tex&quot;&gt;q(x_1)&lt;/script&gt;是初始的observation，&lt;script type=&quot;math/tex&quot;&gt;q(x_{t+1}\vert x_t, a_t)&lt;/script&gt;是transition distribution，而&lt;script type=&quot;math/tex&quot;&gt;H&lt;/script&gt;是episode length。&lt;/p&gt;

&lt;p&gt;因為這篇paper並不只有做在classification的task上，也有做在reinforcement learning上，所以需要有episode的概念，而如果是classification task的話，就會令&lt;script type=&quot;math/tex&quot;&gt;H=1&lt;/script&gt;。&lt;/p&gt;

&lt;h3 id=&quot;maml&quot;&gt;MAML&lt;/h3&gt;

&lt;p&gt;作者提出的概念很直觀，我想要找到一個model初始值，讓這個初始值在各個task上面經過訓練以後都能達到不錯的效果，而我猜想是由於速度上的考量，這邊的&lt;em&gt;經過訓練&lt;/em&gt;指的是經過一次的update，所以可以將objective function寫成以下的樣子&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta_i'=\theta-\alpha\bigtriangledown_\theta \mathcal{L}_{\mathcal{T}_i}(f_\theta)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min\limits_{\theta}\sum\limits_{\mathcal{T}_i \sim p(\mathcal{T})}\mathcal{L}_{\mathcal{T}_i}(f_{\theta_i'})=\sum\limits_{\mathcal{T}_i\sim p(\mathcal{T})}\mathcal{L}_{\mathcal{T}_i}(f_{\theta-\alpha\bigtriangledown_\theta\mathcal{L}_{\mathcal{T}_i}(f_\theta)})&lt;/script&gt;

&lt;p&gt;式(2)是初始參數在task &lt;script type=&quot;math/tex&quot;&gt;\mathcal{T}_i&lt;/script&gt;上經過一次update所得到的參數，式(3)是把在各個task上更新過一次的參數在各個task上的loss加總起來，來當作objective function，而實際更新初始參數的式子如下&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta\leftarrow\theta-\beta\bigtriangledown_\theta\sum\limits_{\mathcal{T}_i\sim p(\mathcal{T})}\mathcal{L}_{\mathcal{T}_i}(f_{\theta_i'})&lt;/script&gt;

&lt;p&gt;如果把其中的&lt;script type=&quot;math/tex&quot;&gt;\theta_i'&lt;/script&gt;用式(2)替換掉的話，可以發現式(4)其實有經過兩次微分，不過tensorflow也有支援兩次微分，所以在實作上可以直接照著paper的公式做出來就行。&lt;/p&gt;

&lt;h3 id=&quot;演算法&quot;&gt;演算法&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;maml-algorithm.png&quot; alt=&quot;Algorithm&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;實驗&quot;&gt;實驗&lt;/h2&gt;

&lt;p&gt;如果想對實驗了解更多的話，可以直接去&lt;a href=&quot;https://arxiv.org/pdf/1703.03400.pdf&quot;&gt;arXiv&lt;/a&gt;上面看原始的paper，這邊只貼上MAML做在classification上的結果，paper還有做在reinforcement learning上的實驗。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;classification-results.png&quot; alt=&quot;Classification results&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到MAML比起其他meta learning的方法都還要來得好一些。&lt;/p&gt;

&lt;h2 id=&quot;結論&quot;&gt;結論&lt;/h2&gt;

&lt;p&gt;作者們提出了簡單卻有效的方式找到好的初始化參數來解meta learning，而且目前deep learning的tool像是tensorflow等都有支援二次微分的計算，所以在實作上應該也不會到非常困難，在paper當中也有附上用tensorflow實作的程式碼。&lt;/p&gt;</content><author><name>Your Name</name></author><category term="Paper" /><category term="Meta-Learning" /><summary type="html">這篇paper想要去尋找一個最佳的初始化參數，讓model可以在各個task上都可以得到不錯的表現。</summary></entry><entry><title type="html">Self-Supervised Generalisation with Meta Auxiliary Learning</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/01/self-supervised-generalisation-with-meta-auxiliary-learning/" rel="alternate" type="text/html" title="Self-Supervised Generalisation with Meta Auxiliary Learning" /><published>2020-03-01T00:00:00+00:00</published><updated>2020-03-01T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/01/self-supervised-generalisation-with-meta-auxiliary-learning</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/03/01/self-supervised-generalisation-with-meta-auxiliary-learning/">&lt;p&gt;通常在訓練的時候，如果能有一些輔助的任務(task)，通常會對主要的任務在效能上有所提升，然而這些輔助任務的答案通常會需要人類來標注，並不能隨意的想加輔助任務就加輔助任務，而這篇文章要介紹的NeurIPS 2019的&lt;a href=&quot;https://papers.nips.cc/paper/8445-self-supervised-generalisation-with-meta-auxiliary-learning.pdf&quot;&gt;Self-Supervised Generalisation with Meta Auxiliary Learning&lt;/a&gt;，將輔助任務的答案都用機器來產生，免去了準備輔助任務答案的麻煩。
&lt;!--more--&gt;&lt;/p&gt;

&lt;h2 id=&quot;簡介&quot;&gt;簡介&lt;/h2&gt;
&lt;p&gt;在先前的研究當中，大多表示如果可以讓model能夠同時有多個任務可以學習，並且共用部分參數的話，對於整體學習的成果會有所提升。&lt;/p&gt;

&lt;p&gt;舉個例子來說，如果今天想要做一個影像辨識的模型，輸入是一張動物的圖片，輸出是該動物的種類，像是貓、狗、鳥等等，我們可以直接疊一些CNN，把圖片丟進去，輸出就直接是動物的種類，gradient descent硬做一波，然而如果我們有更多的資訊，像是知道貓是屬於貓科、狗是屬於犬科，我們可以在model的中間或是在最後額外拉出一條flow來去判別這個動物的科別，通常後者在判斷動物種類的效果應該會比較好，因為在前面CNN的部分更可以知道哪些資訊是需要被保留的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;framework.png&quot; alt=&quot;auxiliary_framework&quot; /&gt;&lt;/p&gt;

&lt;p&gt;不過這樣子的方式其實是很需要人類幫助的，我們需要知道判斷動物種類可以參考科別，而且我們也需要對每一張圖片除了標注種類，還要額外標注科別，答案的獲取相當的昂貴，為此，這篇paper希望能夠讓機器來取代人類，自動產生出一些有意義的輔助答案來幫助主要的任務能學得更好，而上方的圖是這篇paper的示意圖。&lt;/p&gt;

&lt;h2 id=&quot;方法&quot;&gt;方法&lt;/h2&gt;
&lt;h3 id=&quot;model架構圖&quot;&gt;Model架構圖&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;model_architecture.png&quot; alt=&quot;model architecture&quot; /&gt;&lt;/p&gt;

&lt;p&gt;這篇paper將他們所創造出來的model稱之為Meta AuXiliary Learning (MAXL)，由兩個model所組成，分別是在圖片上半部的&lt;em&gt;Multi-task Network&lt;/em&gt;和下半部的&lt;em&gt;Label-Generation Network&lt;/em&gt;。&lt;/p&gt;

&lt;h3 id=&quot;multi-task-network&quot;&gt;Multi-task Network&lt;/h3&gt;

&lt;p&gt;Multi-task Network就是我們主要的neural network，其參數為&lt;script type=&quot;math/tex&quot;&gt;\theta_1&lt;/script&gt;，輸入&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;，輸出primary task和auxiliary task的答案&lt;script type=&quot;math/tex&quot;&gt;f_{\theta_1}^{pri}(x)&lt;/script&gt;和&lt;script type=&quot;math/tex&quot;&gt;f_{\theta_1}^{aux}(x)&lt;/script&gt;，其中auxiliary task的答案&lt;script type=&quot;math/tex&quot;&gt;y^{aux}&lt;/script&gt;是由底下的Label-Generation Network所預測出來的。&lt;/p&gt;

&lt;p&gt;而這個network的目標是希望能夠分對primary task以及auxiliary task，所以它的objective function為&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\arg\limits_{\theta_1}\min\left( \mathcal{L}\left( f_{\theta_1}^{pri}(x_{(i)}), y_{(i)}^{pri} \right) + \mathcal{L} \left( f_{\theta_1}^{aux}(x_{(i)}), y_{(i)}^{aux} \right) \right)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Focal\ loss : \mathcal{L}(\hat y, y)=-y(1-\hat y)^\gamma\log(\hat y)&lt;/script&gt;

&lt;p&gt;其中所使用的loss function為focal loss，在paper裡說可以幫助model更專注在錯誤的predict上。&lt;/p&gt;

&lt;h3 id=&quot;label-generation-network&quot;&gt;Label-Generation Network&lt;/h3&gt;

&lt;p&gt;Label-Generation Network的目的是希望能夠產生出讓Multi-task Network可以學得更好的label，所以它的objective function被設定為&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\arg\limits_{\theta_2}\min\mathcal{L}\left( f_{\theta_1^+}^{pri}(x_{(i)}),y_{(i)}^{pri} \right)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta_1^+=\theta_1-\alpha\bigtriangledown_{\theta_1}\left( \mathcal{L} \left( f_{\theta_1}^{pri}(x_{(i)}), y_{(i)}^{pri} \right) + \mathcal{L} \left( f_{\theta_1}^{aux}(x_{(i)}), y_{(i)}^{aux} \right) \right)&lt;/script&gt;

&lt;p&gt;此objective function的含義是，在Multi-task Network經過一次更新以後，希望它在primary task上的loss可以最小，這個概念有點類似&lt;a href=&quot;https://arxiv.org/pdf/1703.03400.pdf&quot;&gt;MAML&lt;/a&gt;中，希望找到一個初始參數，讓model在更新過後可以在各個task上的綜合表現最佳。&lt;/p&gt;

&lt;p&gt;然而經過他們的實驗發現，用上方的objective function來訓練的話，Label-Generation Network常常會輸出同樣的label，所以在實際上更新的時候會再多加一個regularization loss如下&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta_2=\theta_2-\beta\bigtriangledown_{\theta_2}\left( \mathcal{L}\left( f_{\theta_1^+}^{pri}(x_{(i)}), y_{(i)}^{pri} \right) + \lambda \mathcal{H}(y_{(i)}^{aux})\right)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{H}(\hat y_{(i)})=\sum\limits_{k=1}\limits^{K}\hat y_{(i)}^k\log \hat y_{(i)}^k,\ \ \hat y_{(i)}^k=\frac{1}{N}\sum\limits_{n=1}\limits^{N}\hat y_{(i)}^k[n]&lt;/script&gt;

&lt;p&gt;此regularization loss的意思是，希望在每個batch所產生出來的每個label，它的entropy可以越大越好。&lt;/p&gt;

&lt;p&gt;在一開始讀到這邊的時候，我有一個沒有想通的地方是，從&lt;script type=&quot;math/tex&quot;&gt;\theta_2&lt;/script&gt;更新的式子(5)裡面來看，只有後面regularization的那項跟&lt;script type=&quot;math/tex&quot;&gt;\theta_2&lt;/script&gt;有關，微分中的第一項好像看不出來跟&lt;script type=&quot;math/tex&quot;&gt;\theta_2&lt;/script&gt;有關係，後來探究了一下，發現應該要把第一項展開才能看得出來它跟&lt;script type=&quot;math/tex&quot;&gt;\theta_2&lt;/script&gt;的關係，在式(4)中微分裡面的第二項裡的&lt;script type=&quot;math/tex&quot;&gt;y_{(i)}^{aux}&lt;/script&gt;是由Label-Generation Network產生的，所以式(4)更精確的寫法是&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta_1^+=\theta_1-\alpha\bigtriangledown_{\theta_1}\left( \mathcal{L} \left( f_{\theta_1}^{pri}(x_{(i)}), y_{(i)}^{pri} \right) + \mathcal{L} \left( f_{\theta_1}^{aux}(x_{(i)}), f_{\theta_2}(x_{(i)}) \right) \right)&lt;/script&gt;

&lt;p&gt;式(5)就可以改寫成&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta_2=\theta_2-\beta\bigtriangledown_{\theta_2}\left( \mathcal{L}\left( f_{\theta_1-\alpha\bigtriangledown_{\theta_1}\left( \mathcal{L} \left( f_{\theta_1}^{pri}(x_{(i)}), y_{(i)}^{pri} \right) + \mathcal{L} \left( f_{\theta_1}^{aux}(x_{(i)}), f_{\theta_2}(x_{(i)}) \right) \right)}^{pri}(x_{(i)}), y_{(i)}^{pri} \right) + \lambda \mathcal{H}(y_{(i)}^{aux})\right)&lt;/script&gt;

&lt;p&gt;這時就可以看出來第一項其實也是跟&lt;script type=&quot;math/tex&quot;&gt;\theta_2&lt;/script&gt;有關，只是是二次微分，一個Hessian matrix，好在大多機器學習的工具像是tensorflow和pytorch都有支援Hessian matrix的計算，所以在程式碼裡面只需要寫成式(5)那樣就可以算微分了，可以看&lt;a href=&quot;https://github.com/lorenmt/maxl/blob/master/model_vgg_maxl.py#L402&quot;&gt;paper的原始碼&lt;/a&gt;。&lt;/p&gt;

&lt;h4 id=&quot;mask-softmax&quot;&gt;Mask Softmax&lt;/h4&gt;

&lt;p&gt;在paper裡面有另外提到說，他們覺得在訓練每個不同primary task的類別時，應該給予不一樣的auxiliary label，像是在訓練&lt;script type=&quot;math/tex&quot;&gt;y^{pri}=0&lt;/script&gt;這個類別的時候，所給予的auxiliary label應該就只專門拿來用在&lt;script type=&quot;math/tex&quot;&gt;y^{pri}=0&lt;/script&gt;的情況上，不應該在不同的&lt;script type=&quot;math/tex&quot;&gt;y^{pri}&lt;/script&gt;都給同樣的auxiliary label，所以在Label-Generation Network有一個&lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt;，代表的是對於每個不同的&lt;script type=&quot;math/tex&quot;&gt;y^{pri}&lt;/script&gt;，要給予多少個auxiliary class，如果&lt;script type=&quot;math/tex&quot;&gt;\psi=[2, 2]&lt;/script&gt;的話，就代表給&lt;script type=&quot;math/tex&quot;&gt;y^{pri}=0&lt;/script&gt;兩個auxiliary class，也給&lt;script type=&quot;math/tex&quot;&gt;y^{pri}=1&lt;/script&gt;兩個auxiliary class。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;mask_softmax.png&quot; alt=&quot;mask softmax&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;maxl-algorithm&quot;&gt;MAXL Algorithm&lt;/h3&gt;

&lt;p&gt;下圖為這篇paper附上的algorithm。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;maxl_algorithm.png&quot; alt=&quot;MAXL Algorithm&quot; /&gt;&lt;/p&gt;

&lt;p&gt;簡單來說就是先訓練一下Multi-task Network，接著固定Multi-task Network的參數，抽樣一些訓練資料，算出經過一次更新以後的&lt;script type=&quot;math/tex&quot;&gt;\theta_1^+&lt;/script&gt;，再更新Label-Generation Network。&lt;/p&gt;

&lt;h2 id=&quot;實驗&quot;&gt;實驗&lt;/h2&gt;

&lt;h3 id=&quot;與只有primary-task做比較&quot;&gt;與只有Primary Task做比較&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;compare_to_single_task.png&quot; alt=&quot;Comparison to Single Task&quot; /&gt;&lt;/p&gt;

&lt;p&gt;這邊是用圖形辨識來驗應，Backbone是Multi-task Network的model架構，可以看到MAXL在各個dataset上面都比只用primary task訓練還要來得好，但也只有好一點點。&lt;/p&gt;

&lt;h3 id=&quot;與其他label-generation方法比較&quot;&gt;與其他Label Generation方法比較&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;compare_to_other_methods.png&quot; alt=&quot;Comparison to Other Label Generation Methods&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面比較對象中的K-Means指的是對輸入&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;做一個Autoencoder，對中間的latent representation做K-Means，以輸入&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;屬於哪一個群組來當作label。可以看到MAXL在各個參數的表現上都有不錯的成績，與human在伯仲之間。&lt;/p&gt;

&lt;h3 id=&quot;對model的幫助&quot;&gt;對model的幫助&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;label_usefulness.png&quot; alt=&quot;Gradient Usefulness&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;這邊作者想要知道說，Label-Generation Network所產出的label究竟對model而言有沒有用處，而判斷有沒有用處的依據是去看model對training data上的gradient與對產生出的label的gradient的相似程度。假設training data會帶領model往好的方向邁進，如果產生出的label與training data的gradient相近的話，我們就相信產生出的label是有幫助的。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Similarity = -1 \rightarrow\ 沒有幫助，甚至在扯後腿\\Similarity=0 \rightarrow\ 對model沒什麼影響\\Similarity=1 \rightarrow\ 對model的學習有正向的幫助&lt;/script&gt;

&lt;p&gt;可以看到MAXL的產生出的label與training data的gradient的相似度都介在0~1之間，而且並不像其他方法，隨著訓練過程的推進而相似度下降，代表MAXL有一直在幫助model學習。&lt;/p&gt;

&lt;h3 id=&quot;究竟label-generation-network學到了什麼&quot;&gt;究竟Label-Generation Network學到了什麼&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;visualization.png&quot; alt=&quot;Visualization&quot; /&gt;&lt;/p&gt;

&lt;p&gt;這邊作者想看MAXL產生出來的label究竟是有什麼樣的含義，結論就是其實看不太出來，因為產生出來的label是要給機器看的，人類看不出來也是蠻合理的。&lt;/p&gt;

&lt;h2 id=&quot;結論&quot;&gt;結論&lt;/h2&gt;

&lt;p&gt;這篇paper提出了MAXL，在不需要專業知識以及額外訓練資料的情況下，可以稍微提升model在分類上的準確率，作者表示希望未來可以套用到regression相關的任務上。&lt;/p&gt;</content><author><name>Your Name</name></author><category term="Paper" /><category term="Meta-Learning" /><category term="Auxiliary-Learning" /><summary type="html">通常在訓練的時候，如果能有一些輔助的任務(task)，通常會對主要的任務在效能上有所提升，然而這些輔助任務的答案通常會需要人類來標注，並不能隨意的想加輔助任務就加輔助任務，而這篇文章要介紹的NeurIPS 2019的Self-Supervised Generalisation with Meta Auxiliary Learning，將輔助任務的答案都用機器來產生，免去了準備輔助任務答案的麻煩。</summary></entry><entry><title type="html">如何使用Jekyll建立網站在Github Page上</title><link href="https://wjohn1483.github.io/#%20the%20base%20hostname%20&%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/02/28/create-website-by-Jekyll/" rel="alternate" type="text/html" title="如何使用Jekyll建立網站在Github Page上" /><published>2020-02-28T00:00:00+00:00</published><updated>2020-02-28T00:00:00+00:00</updated><id>https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/02/28/create-website-by-Jekyll</id><content type="html" xml:base="https://wjohn1483.github.io/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site%20e.g.%20https://www.someone.com/2020/02/28/create-website-by-Jekyll/">&lt;p&gt;這篇文章將會簡單介紹一下Jekyll，以及我如何使用Jekyll將網站建置在GitHub Page上的經歷。
&lt;!--more--&gt;&lt;/p&gt;

&lt;h2 id=&quot;jekyll是什麼&quot;&gt;Jekyll是什麼？&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://jekyllrb.com/&quot;&gt;Jekyll&lt;/a&gt;是一個基於Ruby的靜態網頁產生器，常用在個人、project或是公司、組織的網頁上，由GitHub的co-founder &lt;a href=&quot;https://en.wikipedia.org/wiki/Tom_Preston-Werner&quot;&gt;Tom Preston-Wemer&lt;/a&gt;製作的。&lt;/p&gt;

&lt;p&gt;只要給Jekyll一些Liquid模板以及用Markdown寫的文章內容，它就可以幫你生成出一整個靜態網站。
&lt;a href=&quot;https://github.com/Shopify/liquid&quot;&gt;Liquid&lt;/a&gt;是一個模板引擎，可以在html裡面安插一些程式語言，讓html可以根據你的需求被產生出來，可以參考&lt;a href=&quot;https://github.com/Shopify/liquid#what-does-it-look-like&quot;&gt;Liquid GitHub當中的例子&lt;/a&gt;，會比較理解它想要實現的事情。&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;ul&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;id=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;products&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
    
    {% for product in products %}
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;li&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;h2&amp;gt;&lt;/span&gt;{{ product.name  }}&lt;span class=&quot;nt&quot;&gt;&amp;lt;/h2&amp;gt;&lt;/span&gt;
            Only {{ product.price | price  }}

            {{ product.description | prettyprint | paragraph  }}
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/li&amp;gt;&lt;/span&gt;
    {% endfor %}
    
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/ul&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;至於&lt;a href=&quot;https://zh.wikipedia.org/zh-tw/Markdown&quot;&gt;Markdown&lt;/a&gt;，是一個輕量級標記式語言，相信有使用過GitHub的人應該對它並不陌生。&lt;/p&gt;

&lt;p&gt;或許是因為Jekyll是由GitHub co-founder所製作的，所以目前GitHub Page支援Jekyll，使你可以在你的repo當中放入Jekyll的原始碼，GitHub就會自動幫你編譯並部署成網站。
底下將會從零開始，紀錄我如何建立一個部落格網站。&lt;/p&gt;

&lt;h2 id=&quot;準備環境&quot;&gt;準備環境&lt;/h2&gt;
&lt;h3 id=&quot;直接套用現成repo&quot;&gt;直接套用現成Repo&lt;/h3&gt;
&lt;p&gt;如果說不想要這麼麻煩的準備環境，想要直接開始寫作的話，可以去網路上找別人已經弄好的GitHub Repo，像是&lt;a href=&quot;https://github.com/github/personal-website&quot;&gt;personal-website&lt;/a&gt;，Fork到自己的帳號底下，改一下repo的名字，變成&lt;strong&gt;[username].github.io&lt;/strong&gt;，就可以開始在&lt;strong&gt;_post&lt;/strong&gt;這個資料夾底下創立Markdown檔案，開始自由的創作，GitHub理應會將你新創立的文章自動變成網頁部署上去。&lt;/p&gt;

&lt;p&gt;倘若你想要客製化網站的話，可能就必須自己準備一個環境，得要繼續往下閱讀了。&lt;/p&gt;

&lt;h3 id=&quot;建立github-page-repo&quot;&gt;建立GitHub Page Repo&lt;/h3&gt;
&lt;p&gt;網路上有很多教學來教大家如何建立自己的GitHub Page，可以參考&lt;a href=&quot;https://pages.github.com/&quot;&gt;GitHub官方教學&lt;/a&gt;。
其實主要需要做的事情就是建立一個新的repository，命名為&lt;strong&gt;[username].github.io&lt;/strong&gt;，並將之設為public repo。
之後只要將html檔案上傳上去，GitHub就會自動將檔案部署到&lt;strong&gt;https://[username].github.io&lt;/strong&gt;這個網站上，相當的方便而且還免費！&lt;/p&gt;

&lt;h3 id=&quot;安裝rubyjekyll&quot;&gt;安裝Ruby、Jekyll&lt;/h3&gt;
&lt;p&gt;前面有提到Jekyll是基於Ruby所建立的，所以必須要在自己的電腦上先安裝Ruby，安裝Ruby的方法可以參考&lt;a href=&quot;https://jekyllrb.com/docs/installation/&quot;&gt;Jekyll官方教學&lt;/a&gt;，根據不同的作業系統會需要不一樣的步驟，但倘若你所使用的是macOS Catalina以上的作業系統，其內建就有Ruby了，可以直接安裝Jekyll。&lt;/p&gt;

&lt;p&gt;在安裝好Ruby以後，直接下底下的指令應該就能安裝好Jekyll。&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gem &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;bundler jekyll &lt;span class=&quot;nt&quot;&gt;--user-install&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;使用樣板建立第一個網站&quot;&gt;使用樣板建立第一個網站&lt;/h2&gt;
&lt;p&gt;在準備好環境以後，應該就迫不及待的想要產生一個好棒棒的網站，最快的方式應當是去複製別人的樣板，這邊我所使用的樣板是&lt;a href=&quot;https://github.com/kitian616/jekyll-TeXt-theme&quot;&gt;jekyll-TeXt-theme&lt;/a&gt;，你也可以去找尋自己心中所屬的那個樣板，像是蠻像Medium的樣板&lt;a href=&quot;https://github.com/poole/poole&quot;&gt;Poole&lt;/a&gt;等等。&lt;/p&gt;

&lt;p&gt;想好樣板選哪一個以後，接著便是在你的GitHub Page Repo上套用它，套用的流程可以參考底下。&lt;/p&gt;

&lt;h3 id=&quot;clone你的github-page-repo到電腦上&quot;&gt;Clone你的GitHub Page Repo到電腦上&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone https://github.com/[username]/[username].github.io.git
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;在repo根目錄創建gemfile和_confyaml&quot;&gt;在repo根目錄創建Gemfile和_conf.yaml&lt;/h3&gt;

&lt;p&gt;通常樣板都是用gem的形式來讓大家使用，為此我們需要建立&lt;strong&gt;Gemfile&lt;/strong&gt;和&lt;strong&gt;_conf.yaml&lt;/strong&gt;這兩個檔案，來讓Ruby知道我們這個repo需要哪些相關的gem。&lt;/p&gt;

&lt;div class=&quot;language-ruby highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Put the followings into your Gemfile&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;https://rubygems.org&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;gem&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;jekyll&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gem&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;jekyll-text-theme&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Put the following into your _conf.yaml&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;theme&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;jekyll-text-theme&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;安裝套件&quot;&gt;安裝套件&lt;/h3&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;bundle &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--path&lt;/span&gt; vendor/bundle
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;上面的指令會把需要的套件都安裝在&lt;strong&gt;vendor/bundle&lt;/strong&gt;這個資料夾內。&lt;/p&gt;

&lt;h3 id=&quot;把樣板所定義的css設定檔放到repo根目錄&quot;&gt;把樣板所定義的CSS、設定檔放到repo根目錄&lt;/h3&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; vendor/bundle/ruby/2.6.0/gems/jekyll-text-theme-2.2.6/_&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; ./
&lt;span class=&quot;nb&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; vendor/bundle/ruby/2.6.0/gems/jekyll-text-theme-2.2.6/assets ./
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;把網頁模版複製進repo根目錄&quot;&gt;把網頁模版複製進repo根目錄&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/kitian616/jekyll-TeXt-theme&quot;&gt;jekyll-TeXt-theme&lt;/a&gt;所需要的網頁模版可以參考其&lt;a href=&quot;https://github.com/kitian616/jekyll-TeXt-theme/tree/master/test&quot;&gt;repo底下的test資料夾&lt;/a&gt;，我印象中那時是複製了底下這些檔案。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;404.html
_config.yml
archive.html
index.html
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;確認樣板是否順利套用&quot;&gt;確認樣板是否順利套用&lt;/h3&gt;
&lt;p&gt;利用底下的指令讓Jekyll產生靜態網站。&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;bundle &lt;span class=&quot;nb&quot;&gt;exec &lt;/span&gt;jekyll serve &lt;span class=&quot;nt&quot;&gt;--trace&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;產生出來的html檔案們會在&lt;strong&gt;_site/&lt;/strong&gt;這個資料夾內，你也可以到&lt;a href=&quot;http://localhost:4000&quot;&gt;http://localhost:4000&lt;/a&gt;上觀看自己的網頁。&lt;/p&gt;

&lt;p&gt;如果成功看到網頁跑出來，就代表套用算是成功了，接下來就可以開始進行客製化，像是去&lt;strong&gt;_conf.yaml&lt;/strong&gt;做一些設定、調整&lt;strong&gt;_include&lt;/strong&gt;裡面的html模板等等，把網頁刻成你的樣子。&lt;/p&gt;

&lt;h2 id=&quot;部署到github-page上&quot;&gt;部署到GitHub Page上&lt;/h2&gt;
&lt;p&gt;在把網頁變成了你的樣子以後，接著就會想讓世人看看，想把網頁丟到GitHub Page上。
因為Github會自動幫你編譯Jekyll，所以並不需要將整個&lt;strong&gt;_site/&lt;/strong&gt;資料夾上傳，記得把不需要的東西放入&lt;strong&gt;.gitignore&lt;/strong&gt;當中。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;.bundle/
.jekyll-cache/
Gemfile.lock
vendor/
.sass-cache/
.site/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;值得一提的是，因為GitHub在編譯的時候會在safe mode底下執行，所支援的套件有限，可以參考&lt;a href=&quot;https://pages.github.com/versions/&quot;&gt;GitHub Dependency Versions&lt;/a&gt;，如果有用到超出支援的套件的話會編譯不過。&lt;/p&gt;

&lt;p&gt;在push到GitHub以後，可以去repo settings中GitHub Page相關的段落看有沒有錯誤訊息，如果成功部署上去可以看到相關的訊息，如果過程中發生了錯誤，在&lt;a href=&quot;https://help.github.com/en/enterprise/2.14/user/articles/troubleshooting-github-pages-builds&quot;&gt;troubleshooting github page builds&lt;/a&gt;能夠看到更多有關錯誤訊息的資訊。&lt;/p&gt;

&lt;h3 id=&quot;如果我想用超出支援的套件怎麼辦&quot;&gt;如果我想用超出支援的套件怎麼辦？&lt;/h3&gt;
&lt;p&gt;其實Github Page也支援一般的靜態網頁存放方式，所以可以先在本機把網頁編譯好以後，將&lt;strong&gt;_site/&lt;/strong&gt;裡面所有的東西都push到master branch，並放一個&lt;strong&gt;.nojekyll&lt;/strong&gt;的文件在裡面，如此一來就能使用超出支援的套件了，只是是在本機端。&lt;/p&gt;

&lt;p&gt;可以參考&lt;a href=&quot;https://www.drewsilcock.co.uk/custom-jekyll-plugins&quot;&gt;Custom Jekyll plugins with GitHub Pages&lt;/a&gt;，把Jekyll相關的原始碼放進source branch，把產生出來的靜態網頁放進master branch，讓整個東西都還是位在同一個repo底下。&lt;/p&gt;

&lt;p&gt;具體來說那篇文章想做的事情類似底下的指令，但上面文章會把master branch的根目錄設在source branch中的&lt;strong&gt;_site/&lt;/strong&gt;裡面，讓使用者可以編譯完，就進去&lt;strong&gt;_site/&lt;/strong&gt;資料夾內將新產生的html推上master branch。&lt;/p&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Push source to origin and copy site to temp folder&lt;/span&gt;
git checkout &lt;span class=&quot;nt&quot;&gt;-b&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;source
&lt;/span&gt;git push origin &lt;span class=&quot;nb&quot;&gt;source
cp&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; _site/ /tmp/

&lt;span class=&quot;c&quot;&gt;# Remove all files in master&lt;/span&gt;
git checkout master
&lt;span class=&quot;nb&quot;&gt;rm&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-rf&lt;/span&gt; ./&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Copy site to master&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; /tmp/_site/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; ./
&lt;span class=&quot;nb&quot;&gt;touch&lt;/span&gt; .nojekyll

&lt;span class=&quot;c&quot;&gt;# Push master to origin&lt;/span&gt;
git add &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
git commit &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Upload site&quot;&lt;/span&gt;
git push origin master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;如果我想要線上編輯怎麼辦&quot;&gt;如果我想要線上編輯怎麼辦？&lt;/h3&gt;
&lt;p&gt;上面所介紹的方式雖然可以使用沒有支援的套件，但是仍需要在本機編譯，所以每次發佈一篇新的文章時，會需要將新文章的原始碼push到source branch，編譯完成後再進入其中的&lt;strong&gt;_site/&lt;/strong&gt;資料夾把東西push到master branch，這樣才算成功把網頁更新。&lt;/p&gt;

&lt;p&gt;倘若我今天心血來潮在GitHub網頁版上面直接寫起了文章，想要發佈出去的話，還得要打開終端機pull source branch的資料、編譯一下、把東西推到master branch，相當的不方便，所以在此提供一個解法讓你可以在網頁版GitHub的source branch寫完文章以後，commit完可以直接發佈至master branch，於此同時還可以保有使用GitHub Page沒有支援的套件的好處。&lt;/p&gt;

&lt;p&gt;簡述一下解法便是利用Travis CI的虛擬機，幫我們把網頁編譯好，再請它幫我們把編譯好的網站push回master branch。&lt;/p&gt;

&lt;h4 id=&quot;travis-ci-簡介&quot;&gt;Travis CI 簡介&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://travis-ci.org/&quot;&gt;Travis CI&lt;/a&gt;是一個用來作持續整合(CI)的平台，只要在Travis CI連結GitHub，並在repo根目錄當中製作一個&lt;strong&gt;.travis.yml&lt;/strong&gt;檔案，告訴它想要在CI的時候執行什麼樣的指令，它就會建立一個虛擬機並執行你設定的指令。&lt;/p&gt;

&lt;h4 id=&quot;連結travis-ci和github&quot;&gt;連結Travis CI和GitHub&lt;/h4&gt;
&lt;p&gt;到&lt;a href=&quot;https://travis-ci.org/&quot;&gt;Travis CI&lt;/a&gt;的網站中，點選&lt;em&gt;Sign in with GitHub&lt;/em&gt;，並給予它觀看repo的權限，它就可以知道你有哪些repo，接著選擇&lt;strong&gt;[username].github.io&lt;/strong&gt;的repo並勾選右邊的啟動按鈕，如此一來Travis CI就會開始監測你的repo有沒有新的commit。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;activate_ci.png&quot; alt=&quot;Activate Travis CI&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;給予travis-ci-push的權限&quot;&gt;給予Travis CI push的權限&lt;/h4&gt;
&lt;p&gt;為了要讓Travis CI可以幫忙把網頁push到master branch當中，我們需要給予它GitHub token，讓它能夠有權利push，可以到&lt;a href=&quot;https://github.com/settings/tokens&quot;&gt;GitHub settings&lt;/a&gt;創建一個token給Travis CI使用，並勾選給予的權限。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;github_permission.png&quot; alt=&quot;GitHub token permission&quot; /&gt;&lt;/p&gt;

&lt;p&gt;拿到token以後，可以把token儲存在Travis CI的環境變數當中，若把token放repo裡面怕會被別人看到，儲存成變數的方法可以參照&lt;a href=&quot;https://docs.travis-ci.com/user/environment-variables#defining-variables-in-repository-settings&quot;&gt;Travis官方文件&lt;/a&gt;，點選repo的設定以後，就可以找到相關的區塊了，我自己是設定成底下的樣子。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;travis_ci_variable.png&quot; alt=&quot;Travis CI Environment Variables&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;設定travis-ci&quot;&gt;設定Travis CI&lt;/h4&gt;
&lt;p&gt;至此我們讓Travis CI實時監控我們的commit，也讓它有權力可以push到master branch，接著就是告訴它該怎麼樣編譯我們的網站以及要把哪些東西push到master branch。&lt;/p&gt;

&lt;p&gt;我是參照&lt;a href=&quot;https://gist.github.com/willprice/e07efd73fb7f13f917ea#file-travis-yml&quot;&gt;別人的gist&lt;/a&gt;稍作修改以後來設定的，可以參考我的&lt;a href=&quot;https://github.com/wjohn1483/wjohn1483.github.io/blob/source/.travis.yml&quot;&gt;.travis.yml&lt;/a&gt;和&lt;a href=&quot;https://github.com/wjohn1483/wjohn1483.github.io/blob/source/.travis/push.sh&quot;&gt;.travis/push.sh&lt;/a&gt;。&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# .travis.yml&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;language&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ruby&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;rvm&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2.1&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;bundle exec jekyll build&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;after_success&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;$TRAVIS_PULL_REQUEST&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;false&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;];&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;then&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;bash&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-x&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;.travis/push.sh;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;fi'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# .travis/push.sh&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;

setup_git_folder&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    git init
    git config &lt;span class=&quot;nt&quot;&gt;--global&lt;/span&gt; user.email &lt;span class=&quot;s2&quot;&gt;&quot;wjohn1483@yahoo.com.tw&quot;&lt;/span&gt;
    git config &lt;span class=&quot;nt&quot;&gt;--global&lt;/span&gt; user.name &lt;span class=&quot;s2&quot;&gt;&quot;wjohn1483&quot;&lt;/span&gt;
    git remote add origin https://&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;GITHUB_TOKEN&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;@github.com/wjohn1483/wjohn1483.github.io.git
    git pull origin master
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

commit_website_files&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    git checkout master
    rsync &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--delete-after&lt;/span&gt; ../_site/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; ./
    git status
    git add &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
    git commit &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Travis build: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TRAVIS_BUILD_NUMBER&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

upload_files&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    git push origin master
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;mkdir &lt;/span&gt;folder_to_push
&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;folder_to_push

setup_git_folder
commit_website_files
upload_files
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;至此就完成了線上編輯的所有步驟了，以後就能夠在GitHub網頁版上撰寫文章，commit完就直接部署到GitHub Page上。&lt;/p&gt;</content><author><name>Your Name</name></author><category term="Tool" /><summary type="html">這篇文章將會簡單介紹一下Jekyll，以及我如何使用Jekyll將網站建置在GitHub Page上的經歷。</summary></entry></feed>